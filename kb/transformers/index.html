<!DOCTYPE html>
<html lang="nl" class="scroll-smooth">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="Wat zijn Transformers? De architectuur achter GPT, BERT en alle moderne LLMs uitgelegd. Van attention mechanism tot encoder-decoder modellen.">
    <title>What are Transformers? | Virtunet Knowledge Base</title>

    <!-- Tailwind CSS -->
    <script src="https://cdn.tailwindcss.com"></script>
    <script src="../../js/tailwind-config.js"></script>

    <!-- Fonts & Icons -->
    <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700&family=Poppins:wght@500;600;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">

    <style>
        .prose h2 { scroll-margin-top: 100px; }
        .prose h3 { scroll-margin-top: 100px; }
    </style>
</head>
<body class="bg-white dark:bg-slate-900 text-slate-900 dark:text-slate-50 font-sans antialiased selection:bg-primary selection:text-white transition-colors duration-300">

    <!-- Navbar -->
    <nav class="fixed w-full z-50 bg-white/80 dark:bg-slate-900/80 backdrop-blur-md border-b border-slate-200 dark:border-slate-800 transition-colors duration-300">
        <div class="max-w-7xl mx-auto px-4 sm:px-6 lg:px-8">
            <div class="flex items-center justify-between h-20">
                <!-- Logo -->
                <div class="flex-shrink-0">
                    <a href="../../" class="flex items-center gap-3 group">
                        <div class="w-10 h-10 rounded-lg bg-gradient-to-br from-primary-500 to-purple-600 shadow-lg shadow-primary-500/20 group-hover:scale-110 transition-transform flex items-center justify-center text-white font-bold text-xl font-display">
                            V
                        </div>
                        <span class="font-display font-bold text-xl tracking-tight text-slate-900 dark:text-white">Virtunet</span>
                    </a>
                </div>

                <!-- Desktop Menu -->
                <div class="hidden md:flex items-center gap-8">
                    <a href="../../#services" class="text-sm font-medium text-slate-600 dark:text-slate-300 hover:text-primary-600 dark:hover:text-white transition-colors">Expertise</a>
                    <a href="../../#projects" class="text-sm font-medium text-slate-600 dark:text-slate-300 hover:text-primary-600 dark:hover:text-white transition-colors">Projecten</a>
                    <a href="../../value-proposition/" class="text-sm font-medium text-slate-600 dark:text-slate-300 hover:text-primary-600 dark:hover:text-white transition-colors">Aanpak</a>
                    <a href="../../whitepapers/" class="text-sm font-medium text-slate-600 dark:text-slate-300 hover:text-primary-600 dark:hover:text-white transition-colors">Insights</a>
                    <a href="../../kb/" class="text-sm font-medium text-primary-600 dark:text-primary-400 hover:text-primary-700 dark:hover:text-primary-300 transition-colors">Knowledge Base</a>

                    <div class="flex items-center gap-4 ml-4 pl-4 border-l border-slate-200 dark:border-slate-700">
                        <button onclick="toggleTheme()" class="p-2 rounded-full text-slate-500 hover:bg-slate-100 dark:text-slate-400 dark:hover:bg-slate-800 transition-colors" aria-label="Toggle Dark Mode">
                            <i class="fas fa-sun hidden dark:block"></i>
                            <i class="fas fa-moon block dark:hidden"></i>
                        </button>
                        <a href="../../#contact" class="bg-primary-600 hover:bg-primary-700 text-white px-5 py-2.5 rounded-full text-sm font-medium transition-all shadow-lg shadow-primary-500/25 hover:shadow-primary-500/40 hover:-translate-y-0.5">Contact</a>
                    </div>
                </div>

                <!-- Mobile menu button -->
                <div class="md:hidden flex items-center gap-4">
                    <button onclick="toggleTheme()" class="p-2 rounded-full text-slate-500 hover:bg-slate-100 dark:text-slate-400 dark:hover:bg-slate-800 transition-colors">
                        <i class="fas fa-sun hidden dark:block"></i>
                        <i class="fas fa-moon block dark:hidden"></i>
                    </button>
                    <button type="button" class="p-2 rounded-md text-slate-600 dark:text-slate-300 hover:bg-slate-100 dark:hover:bg-slate-800 transition-colors" id="mobile-menu-btn">
                        <i class="fas fa-bars text-xl"></i>
                    </button>
                </div>
            </div>
        </div>

        <!-- Mobile Menu -->
        <div class="md:hidden hidden bg-white dark:bg-slate-900 border-b border-slate-200 dark:border-slate-800" id="mobile-menu">
            <div class="px-4 pt-2 pb-6 space-y-1">
                <a href="../../#services" class="block px-3 py-3 rounded-md text-base font-medium text-slate-600 dark:text-slate-300 hover:bg-slate-50 dark:hover:bg-slate-800">Expertise</a>
                <a href="../../#projects" class="block px-3 py-3 rounded-md text-base font-medium text-slate-600 dark:text-slate-300 hover:bg-slate-50 dark:hover:bg-slate-800">Projecten</a>
                <a href="../../value-proposition/" class="block px-3 py-3 rounded-md text-base font-medium text-slate-600 dark:text-slate-300 hover:bg-slate-50 dark:hover:bg-slate-800">Aanpak</a>
                <a href="../../whitepapers/" class="block px-3 py-3 rounded-md text-base font-medium text-slate-600 dark:text-slate-300 hover:bg-slate-50 dark:hover:bg-slate-800">Insights</a>
                <a href="../../kb/" class="block px-3 py-3 rounded-md text-base font-medium text-primary-600 dark:text-primary-400 hover:bg-slate-50 dark:hover:bg-slate-800">Knowledge Base</a>
                <a href="../../#contact" class="block mt-4 text-center bg-primary-600 text-white px-3 py-3 rounded-lg font-medium">Contact</a>
            </div>
        </div>
    </nav>

    <!-- Article Header -->
    <header class="pt-32 pb-12 relative overflow-hidden bg-gradient-to-b from-purple-600 to-violet-700">
        <div class="absolute inset-0 bg-grid-white/[0.05] bg-[length:20px_20px]"></div>
        <div class="absolute top-0 left-1/2 -translate-x-1/2 w-[800px] h-[400px] bg-white/10 rounded-full blur-3xl pointer-events-none"></div>

        <div class="container mx-auto px-4 max-w-4xl relative z-10">
            <!-- Breadcrumb -->
            <nav class="flex items-center gap-2 text-sm text-purple-200 mb-6">
                <a href="../../kb/" class="hover:text-white transition-colors">Knowledge Base</a>
                <i class="fas fa-chevron-right text-xs"></i>
                <span class="text-white">Generative AI</span>
            </nav>

            <!-- Category & Meta -->
            <div class="flex flex-wrap items-center gap-4 mb-6">
                <span class="px-3 py-1 rounded-full text-xs font-bold bg-white/20 text-white backdrop-blur-sm">Generative AI</span>
                <span class="text-purple-200 text-sm"><i class="far fa-clock mr-1"></i> 12 min read</span>
                <span class="text-purple-200 text-sm"><i class="far fa-calendar mr-1"></i> December 2024</span>
            </div>

            <h1 class="text-4xl md:text-5xl font-display font-bold text-white mb-6">
                What are Transformers?
            </h1>
            <p class="text-xl text-purple-100 leading-relaxed max-w-3xl">
                De architectuur achter GPT, BERT en alle moderne Large Language Models. Begrijp hoe attention mechanism de AI-wereld heeft veranderd.
            </p>
        </div>
    </header>

    <!-- Article Content -->
    <article class="py-16 bg-white dark:bg-slate-900 transition-colors duration-300">
        <div class="container mx-auto px-4">
            <div class="max-w-4xl mx-auto">

                <!-- Table of Contents -->
                <div class="bg-slate-50 dark:bg-slate-850 rounded-2xl p-6 border border-slate-200 dark:border-slate-800 mb-12">
                    <h2 class="font-bold text-slate-900 dark:text-white mb-4 flex items-center gap-2">
                        <i class="fas fa-list text-primary-500"></i> In dit artikel
                    </h2>
                    <nav class="space-y-2">
                        <a href="#introductie" class="block text-slate-600 dark:text-slate-400 hover:text-primary-600 dark:hover:text-primary-400 transition-colors">1. Introductie: Waarom Transformers?</a>
                        <a href="#attention" class="block text-slate-600 dark:text-slate-400 hover:text-primary-600 dark:hover:text-primary-400 transition-colors">2. Attention is All You Need</a>
                        <a href="#self-attention" class="block text-slate-600 dark:text-slate-400 hover:text-primary-600 dark:hover:text-primary-400 transition-colors">3. Self-Attention uitgelegd</a>
                        <a href="#architectuur" class="block text-slate-600 dark:text-slate-400 hover:text-primary-600 dark:hover:text-primary-400 transition-colors">4. De Transformer Architectuur</a>
                        <a href="#varianten" class="block text-slate-600 dark:text-slate-400 hover:text-primary-600 dark:hover:text-primary-400 transition-colors">5. Encoder vs Decoder varianten</a>
                        <a href="#toepassingen" class="block text-slate-600 dark:text-slate-400 hover:text-primary-600 dark:hover:text-primary-400 transition-colors">6. Bekende Transformer modellen</a>
                    </nav>
                </div>

                <!-- Content -->
                <div class="prose prose-lg dark:prose-invert max-w-none">

                    <!-- Section 1 -->
                    <h2 id="introductie" class="text-2xl font-display font-bold text-slate-900 dark:text-white mt-12 mb-6 flex items-center gap-3">
                        <span class="w-10 h-10 rounded-lg bg-purple-100 dark:bg-purple-500/10 flex items-center justify-center text-purple-600 dark:text-purple-400 text-lg font-bold">1</span>
                        Introductie: Waarom Transformers?
                    </h2>

                    <p class="text-slate-600 dark:text-slate-400 leading-relaxed mb-6">
                        Vóór 2017 waren <strong class="text-slate-900 dark:text-white">Recurrent Neural Networks (RNNs)</strong> en <strong class="text-slate-900 dark:text-white">LSTMs</strong> de standaard voor taalverwerking. Ze hadden één groot probleem: ze verwerken tekst sequentieel, woord voor woord.
                    </p>

                    <p class="text-slate-600 dark:text-slate-400 leading-relaxed mb-6">
                        Dit betekende:
                    </p>

                    <ul class="space-y-3 mb-8">
                        <li class="flex gap-3 text-slate-600 dark:text-slate-400">
                            <i class="fas fa-times text-red-500 mt-1.5"></i>
                            <span><strong class="text-slate-900 dark:text-white">Langzame training:</strong> Geen parallellisatie mogelijk, elke stap wacht op de vorige</span>
                        </li>
                        <li class="flex gap-3 text-slate-600 dark:text-slate-400">
                            <i class="fas fa-times text-red-500 mt-1.5"></i>
                            <span><strong class="text-slate-900 dark:text-white">Korte-termijn geheugen:</strong> Context van vroege woorden "vervaagt" bij lange zinnen</span>
                        </li>
                        <li class="flex gap-3 text-slate-600 dark:text-slate-400">
                            <i class="fas fa-times text-red-500 mt-1.5"></i>
                            <span><strong class="text-slate-900 dark:text-white">Beperkte schaalbaarheid:</strong> Moeilijk om grotere modellen te trainen</span>
                        </li>
                    </ul>

                    <p class="text-slate-600 dark:text-slate-400 leading-relaxed mb-6">
                        In 2017 publiceerde Google het baanbrekende paper <em>"Attention Is All You Need"</em> dat de <strong class="text-slate-900 dark:text-white">Transformer</strong> architectuur introduceerde — en alles veranderde.
                    </p>

                    <!-- Section 2 -->
                    <h2 id="attention" class="text-2xl font-display font-bold text-slate-900 dark:text-white mt-16 mb-6 flex items-center gap-3">
                        <span class="w-10 h-10 rounded-lg bg-purple-100 dark:bg-purple-500/10 flex items-center justify-center text-purple-600 dark:text-purple-400 text-lg font-bold">2</span>
                        Attention is All You Need
                    </h2>

                    <p class="text-slate-600 dark:text-slate-400 leading-relaxed mb-6">
                        Het kernidee van Transformers is het <strong class="text-slate-900 dark:text-white">attention mechanism</strong>. In plaats van woorden één voor één te verwerken, kan een Transformer naar de hele zin tegelijk kijken en bepalen welke woorden relevant zijn voor elk ander woord.
                    </p>

                    <div class="bg-purple-50 dark:bg-purple-500/10 border border-purple-200 dark:border-purple-500/20 rounded-xl p-6 mb-8">
                        <div class="flex gap-4">
                            <div class="flex-shrink-0 w-12 h-12 rounded-full bg-purple-100 dark:bg-purple-500/20 flex items-center justify-center text-purple-600 dark:text-purple-400">
                                <i class="fas fa-lightbulb text-xl"></i>
                            </div>
                            <div>
                                <h4 class="font-bold text-slate-900 dark:text-white mb-2">Analogie</h4>
                                <p class="text-slate-600 dark:text-slate-400 text-sm">
                                    Stel je voor dat je een boek leest. RNNs lezen woord voor woord en moeten alles onthouden. Transformers kunnen elk woord "tegelijk zien" en bij elk woord terugbladeren naar relevante passages — alsof je een boek met hyperlinks leest.
                                </p>
                            </div>
                        </div>
                    </div>

                    <!-- Section 3 -->
                    <h2 id="self-attention" class="text-2xl font-display font-bold text-slate-900 dark:text-white mt-16 mb-6 flex items-center gap-3">
                        <span class="w-10 h-10 rounded-lg bg-purple-100 dark:bg-purple-500/10 flex items-center justify-center text-purple-600 dark:text-purple-400 text-lg font-bold">3</span>
                        Self-Attention uitgelegd
                    </h2>

                    <p class="text-slate-600 dark:text-slate-400 leading-relaxed mb-6">
                        <strong class="text-slate-900 dark:text-white">Self-attention</strong> berekent voor elk woord in een zin hoe relevant elk ander woord is. Dit gebeurt via drie vectoren per woord:
                    </p>

                    <!-- QKV Diagram -->
                    <div class="bg-slate-50 dark:bg-slate-850 rounded-2xl p-8 border border-slate-200 dark:border-slate-800 mb-8">
                        <div class="grid md:grid-cols-3 gap-6 mb-6">
                            <div class="text-center">
                                <div class="w-16 h-16 rounded-full bg-blue-100 dark:bg-blue-500/10 flex items-center justify-center text-blue-600 dark:text-blue-400 mx-auto mb-3 text-2xl font-bold">
                                    Q
                                </div>
                                <h5 class="font-bold text-slate-900 dark:text-white">Query</h5>
                                <p class="text-sm text-slate-500 dark:text-slate-400">"Waar zoek ik naar?"</p>
                            </div>
                            <div class="text-center">
                                <div class="w-16 h-16 rounded-full bg-emerald-100 dark:bg-emerald-500/10 flex items-center justify-center text-emerald-600 dark:text-emerald-400 mx-auto mb-3 text-2xl font-bold">
                                    K
                                </div>
                                <h5 class="font-bold text-slate-900 dark:text-white">Key</h5>
                                <p class="text-sm text-slate-500 dark:text-slate-400">"Wat heb ik te bieden?"</p>
                            </div>
                            <div class="text-center">
                                <div class="w-16 h-16 rounded-full bg-amber-100 dark:bg-amber-500/10 flex items-center justify-center text-amber-600 dark:text-amber-400 mx-auto mb-3 text-2xl font-bold">
                                    V
                                </div>
                                <h5 class="font-bold text-slate-900 dark:text-white">Value</h5>
                                <p class="text-sm text-slate-500 dark:text-slate-400">"Mijn daadwerkelijke inhoud"</p>
                            </div>
                        </div>
                        <p class="text-center text-sm text-slate-500 dark:text-slate-400">
                            Attention Score = softmax(Q · K<sup>T</sup> / √d) × V
                        </p>
                    </div>

                    <p class="text-slate-600 dark:text-slate-400 leading-relaxed mb-6">
                        Voorbeeld met de zin: <em>"De kat zat op de mat omdat hij moe was"</em>
                    </p>

                    <p class="text-slate-600 dark:text-slate-400 leading-relaxed mb-6">
                        Bij het woord "hij" bepaalt self-attention dat "kat" het meest relevant is — het model leert dat "hij" naar "kat" verwijst, niet naar "mat".
                    </p>

                    <!-- Attention Visualization -->
                    <div class="bg-white dark:bg-slate-900 rounded-xl p-6 border border-slate-200 dark:border-slate-800 mb-8">
                        <h4 class="font-bold text-slate-900 dark:text-white mb-4">Attention weights voorbeeld</h4>
                        <div class="overflow-x-auto">
                            <table class="w-full text-sm">
                                <thead>
                                    <tr class="border-b border-slate-200 dark:border-slate-700">
                                        <th class="text-left p-2 text-slate-500">→</th>
                                        <th class="p-2 text-slate-600 dark:text-slate-400">De</th>
                                        <th class="p-2 text-slate-600 dark:text-slate-400">kat</th>
                                        <th class="p-2 text-slate-600 dark:text-slate-400">zat</th>
                                        <th class="p-2 text-slate-600 dark:text-slate-400">op</th>
                                        <th class="p-2 text-slate-600 dark:text-slate-400">de</th>
                                        <th class="p-2 text-slate-600 dark:text-slate-400">mat</th>
                                        <th class="p-2 text-slate-600 dark:text-slate-400">omdat</th>
                                        <th class="p-2 text-purple-600 dark:text-purple-400 font-bold">hij</th>
                                        <th class="p-2 text-slate-600 dark:text-slate-400">moe</th>
                                        <th class="p-2 text-slate-600 dark:text-slate-400">was</th>
                                    </tr>
                                </thead>
                                <tbody>
                                    <tr>
                                        <td class="p-2 font-bold text-purple-600 dark:text-purple-400">hij</td>
                                        <td class="p-2 text-slate-400">0.02</td>
                                        <td class="p-2 text-purple-600 dark:text-purple-400 font-bold bg-purple-50 dark:bg-purple-500/10">0.68</td>
                                        <td class="p-2 text-slate-400">0.05</td>
                                        <td class="p-2 text-slate-400">0.01</td>
                                        <td class="p-2 text-slate-400">0.02</td>
                                        <td class="p-2 text-slate-400">0.03</td>
                                        <td class="p-2 text-slate-400">0.04</td>
                                        <td class="p-2 text-slate-400">0.05</td>
                                        <td class="p-2 text-slate-400">0.05</td>
                                        <td class="p-2 text-slate-400">0.05</td>
                                    </tr>
                                </tbody>
                            </table>
                        </div>
                        <p class="text-xs text-slate-500 dark:text-slate-400 mt-4">
                            Het model heeft geleerd dat "hij" vooral naar "kat" verwijst (0.68 attention weight)
                        </p>
                    </div>

                    <!-- Section 4 -->
                    <h2 id="architectuur" class="text-2xl font-display font-bold text-slate-900 dark:text-white mt-16 mb-6 flex items-center gap-3">
                        <span class="w-10 h-10 rounded-lg bg-purple-100 dark:bg-purple-500/10 flex items-center justify-center text-purple-600 dark:text-purple-400 text-lg font-bold">4</span>
                        De Transformer Architectuur
                    </h2>

                    <p class="text-slate-600 dark:text-slate-400 leading-relaxed mb-6">
                        Een volledige Transformer bestaat uit twee delen: een <strong class="text-slate-900 dark:text-white">Encoder</strong> en een <strong class="text-slate-900 dark:text-white">Decoder</strong>.
                    </p>

                    <!-- Architecture Diagram -->
                    <div class="bg-slate-50 dark:bg-slate-850 rounded-2xl p-8 border border-slate-200 dark:border-slate-800 mb-8">
                        <div class="grid md:grid-cols-2 gap-8">
                            <!-- Encoder -->
                            <div class="bg-white dark:bg-slate-900 rounded-xl p-6 border border-purple-200 dark:border-purple-500/30">
                                <h4 class="font-bold text-purple-600 dark:text-purple-400 mb-4 text-center">Encoder</h4>
                                <div class="space-y-3">
                                    <div class="bg-purple-100 dark:bg-purple-500/10 rounded-lg p-3 text-center text-sm font-medium text-purple-700 dark:text-purple-300">
                                        Input Embedding + Positional Encoding
                                    </div>
                                    <div class="flex justify-center">
                                        <i class="fas fa-arrow-down text-slate-300"></i>
                                    </div>
                                    <div class="bg-purple-100 dark:bg-purple-500/10 rounded-lg p-3 text-center text-sm font-medium text-purple-700 dark:text-purple-300">
                                        Multi-Head Self-Attention
                                    </div>
                                    <div class="flex justify-center">
                                        <i class="fas fa-arrow-down text-slate-300"></i>
                                    </div>
                                    <div class="bg-purple-100 dark:bg-purple-500/10 rounded-lg p-3 text-center text-sm font-medium text-purple-700 dark:text-purple-300">
                                        Add & Normalize
                                    </div>
                                    <div class="flex justify-center">
                                        <i class="fas fa-arrow-down text-slate-300"></i>
                                    </div>
                                    <div class="bg-purple-100 dark:bg-purple-500/10 rounded-lg p-3 text-center text-sm font-medium text-purple-700 dark:text-purple-300">
                                        Feed Forward Network
                                    </div>
                                    <div class="flex justify-center">
                                        <i class="fas fa-arrow-down text-slate-300"></i>
                                    </div>
                                    <div class="bg-purple-100 dark:bg-purple-500/10 rounded-lg p-3 text-center text-sm font-medium text-purple-700 dark:text-purple-300">
                                        Add & Normalize
                                    </div>
                                </div>
                                <p class="text-xs text-slate-500 mt-4 text-center">× N layers</p>
                            </div>

                            <!-- Decoder -->
                            <div class="bg-white dark:bg-slate-900 rounded-xl p-6 border border-violet-200 dark:border-violet-500/30">
                                <h4 class="font-bold text-violet-600 dark:text-violet-400 mb-4 text-center">Decoder</h4>
                                <div class="space-y-3">
                                    <div class="bg-violet-100 dark:bg-violet-500/10 rounded-lg p-3 text-center text-sm font-medium text-violet-700 dark:text-violet-300">
                                        Output Embedding + Positional Encoding
                                    </div>
                                    <div class="flex justify-center">
                                        <i class="fas fa-arrow-down text-slate-300"></i>
                                    </div>
                                    <div class="bg-violet-100 dark:bg-violet-500/10 rounded-lg p-3 text-center text-sm font-medium text-violet-700 dark:text-violet-300">
                                        Masked Multi-Head Attention
                                    </div>
                                    <div class="flex justify-center">
                                        <i class="fas fa-arrow-down text-slate-300"></i>
                                    </div>
                                    <div class="bg-violet-100 dark:bg-violet-500/10 rounded-lg p-3 text-center text-sm font-medium text-violet-700 dark:text-violet-300">
                                        Cross-Attention (naar Encoder)
                                    </div>
                                    <div class="flex justify-center">
                                        <i class="fas fa-arrow-down text-slate-300"></i>
                                    </div>
                                    <div class="bg-violet-100 dark:bg-violet-500/10 rounded-lg p-3 text-center text-sm font-medium text-violet-700 dark:text-violet-300">
                                        Feed Forward + Output
                                    </div>
                                </div>
                                <p class="text-xs text-slate-500 mt-4 text-center">× N layers</p>
                            </div>
                        </div>
                    </div>

                    <p class="text-slate-600 dark:text-slate-400 leading-relaxed mb-6">
                        Belangrijke componenten:
                    </p>

                    <ul class="space-y-3 mb-8">
                        <li class="flex gap-3 text-slate-600 dark:text-slate-400">
                            <i class="fas fa-check text-purple-500 mt-1.5"></i>
                            <span><strong class="text-slate-900 dark:text-white">Positional Encoding:</strong> Geeft het model informatie over de volgorde van woorden (anders weet het niet dat "kat bijt hond" ≠ "hond bijt kat")</span>
                        </li>
                        <li class="flex gap-3 text-slate-600 dark:text-slate-400">
                            <i class="fas fa-check text-purple-500 mt-1.5"></i>
                            <span><strong class="text-slate-900 dark:text-white">Multi-Head Attention:</strong> Meerdere attention-berekeningen parallel, zodat het model verschillende types relaties kan leren</span>
                        </li>
                        <li class="flex gap-3 text-slate-600 dark:text-slate-400">
                            <i class="fas fa-check text-purple-500 mt-1.5"></i>
                            <span><strong class="text-slate-900 dark:text-white">Residual Connections:</strong> Skip connections die training van diepe netwerken stabiel houden</span>
                        </li>
                    </ul>

                    <!-- Section 5 -->
                    <h2 id="varianten" class="text-2xl font-display font-bold text-slate-900 dark:text-white mt-16 mb-6 flex items-center gap-3">
                        <span class="w-10 h-10 rounded-lg bg-purple-100 dark:bg-purple-500/10 flex items-center justify-center text-purple-600 dark:text-purple-400 text-lg font-bold">5</span>
                        Encoder vs Decoder varianten
                    </h2>

                    <p class="text-slate-600 dark:text-slate-400 leading-relaxed mb-6">
                        Niet alle Transformer-modellen gebruiken beide delen. Er zijn drie hoofdvarianten:
                    </p>

                    <!-- Variants Comparison -->
                    <div class="grid md:grid-cols-3 gap-6 mb-8">
                        <div class="bg-blue-50 dark:bg-blue-500/10 border border-blue-200 dark:border-blue-500/20 rounded-xl p-6">
                            <h4 class="font-bold text-slate-900 dark:text-white mb-2">Encoder-only</h4>
                            <p class="text-sm text-slate-600 dark:text-slate-400 mb-4">Begrijpt tekst, genereert niet</p>
                            <div class="text-xs space-y-1">
                                <div class="flex items-center gap-2 text-slate-500 dark:text-slate-400">
                                    <i class="fas fa-robot"></i>
                                    <span>BERT, RoBERTa</span>
                                </div>
                                <div class="flex items-center gap-2 text-slate-500 dark:text-slate-400">
                                    <i class="fas fa-tasks"></i>
                                    <span>Classificatie, NER</span>
                                </div>
                            </div>
                        </div>

                        <div class="bg-purple-50 dark:bg-purple-500/10 border border-purple-200 dark:border-purple-500/20 rounded-xl p-6">
                            <h4 class="font-bold text-slate-900 dark:text-white mb-2">Decoder-only</h4>
                            <p class="text-sm text-slate-600 dark:text-slate-400 mb-4">Genereert tekst (autoregressive)</p>
                            <div class="text-xs space-y-1">
                                <div class="flex items-center gap-2 text-slate-500 dark:text-slate-400">
                                    <i class="fas fa-robot"></i>
                                    <span>GPT, LLaMA, Claude</span>
                                </div>
                                <div class="flex items-center gap-2 text-slate-500 dark:text-slate-400">
                                    <i class="fas fa-tasks"></i>
                                    <span>Text generation, chat</span>
                                </div>
                            </div>
                        </div>

                        <div class="bg-emerald-50 dark:bg-emerald-500/10 border border-emerald-200 dark:border-emerald-500/20 rounded-xl p-6">
                            <h4 class="font-bold text-slate-900 dark:text-white mb-2">Encoder-Decoder</h4>
                            <p class="text-sm text-slate-600 dark:text-slate-400 mb-4">Input → Output transformatie</p>
                            <div class="text-xs space-y-1">
                                <div class="flex items-center gap-2 text-slate-500 dark:text-slate-400">
                                    <i class="fas fa-robot"></i>
                                    <span>T5, BART</span>
                                </div>
                                <div class="flex items-center gap-2 text-slate-500 dark:text-slate-400">
                                    <i class="fas fa-tasks"></i>
                                    <span>Vertaling, summarization</span>
                                </div>
                            </div>
                        </div>
                    </div>

                    <!-- Section 6 -->
                    <h2 id="toepassingen" class="text-2xl font-display font-bold text-slate-900 dark:text-white mt-16 mb-6 flex items-center gap-3">
                        <span class="w-10 h-10 rounded-lg bg-purple-100 dark:bg-purple-500/10 flex items-center justify-center text-purple-600 dark:text-purple-400 text-lg font-bold">6</span>
                        Bekende Transformer modellen
                    </h2>

                    <!-- Models Timeline -->
                    <div class="space-y-4 mb-8">
                        <div class="flex gap-4 p-4 bg-slate-50 dark:bg-slate-850 rounded-xl border border-slate-200 dark:border-slate-800">
                            <div class="w-16 text-center">
                                <span class="text-xs text-slate-500">2017</span>
                            </div>
                            <div>
                                <h5 class="font-bold text-slate-900 dark:text-white">Original Transformer</h5>
                                <p class="text-sm text-slate-600 dark:text-slate-400">Google's paper "Attention Is All You Need" — bewees dat attention alleen voldoende is</p>
                            </div>
                        </div>

                        <div class="flex gap-4 p-4 bg-slate-50 dark:bg-slate-850 rounded-xl border border-slate-200 dark:border-slate-800">
                            <div class="w-16 text-center">
                                <span class="text-xs text-slate-500">2018</span>
                            </div>
                            <div>
                                <h5 class="font-bold text-slate-900 dark:text-white">BERT (Google) & GPT (OpenAI)</h5>
                                <p class="text-sm text-slate-600 dark:text-slate-400">BERT voor begrip (encoder), GPT voor generatie (decoder) — twee paradigma's ontstaan</p>
                            </div>
                        </div>

                        <div class="flex gap-4 p-4 bg-slate-50 dark:bg-slate-850 rounded-xl border border-slate-200 dark:border-slate-800">
                            <div class="w-16 text-center">
                                <span class="text-xs text-slate-500">2020</span>
                            </div>
                            <div>
                                <h5 class="font-bold text-slate-900 dark:text-white">GPT-3</h5>
                                <p class="text-sm text-slate-600 dark:text-slate-400">175 miljard parameters — bewees dat schaal "emergente" capabilities geeft</p>
                            </div>
                        </div>

                        <div class="flex gap-4 p-4 bg-purple-50 dark:bg-purple-500/10 rounded-xl border border-purple-200 dark:border-purple-500/20">
                            <div class="w-16 text-center">
                                <span class="text-xs text-purple-600 dark:text-purple-400">2022+</span>
                            </div>
                            <div>
                                <h5 class="font-bold text-slate-900 dark:text-white">ChatGPT, GPT-4, Claude, LLaMA</h5>
                                <p class="text-sm text-slate-600 dark:text-slate-400">Instruction tuning + RLHF maakt modellen bruikbaar voor gesprekken</p>
                            </div>
                        </div>
                    </div>

                    <!-- Key Takeaway -->
                    <div class="bg-purple-50 dark:bg-purple-500/10 border border-purple-200 dark:border-purple-500/20 rounded-xl p-6 mb-8">
                        <h4 class="font-bold text-slate-900 dark:text-white mb-2 flex items-center gap-2">
                            <i class="fas fa-graduation-cap text-purple-500"></i>
                            Key Takeaway
                        </h4>
                        <p class="text-slate-600 dark:text-slate-400 text-sm">
                            De Transformer architectuur is de basis van vrijwel alle moderne AI-doorbraken. Het attention mechanism maakte het mogelijk om parallel te trainen op gigantische datasets en lange-afstand relaties in tekst te modelleren — de sleutel tot GPT en alle LLMs die volgden.
                        </p>
                    </div>

                </div>

                <!-- Related Articles -->
                <div class="mt-16 pt-12 border-t border-slate-200 dark:border-slate-800">
                    <h3 class="text-xl font-display font-bold text-slate-900 dark:text-white mb-6">Gerelateerde artikelen</h3>
                    <div class="grid md:grid-cols-2 gap-6">
                        <a href="../how-llms-work/" class="group flex gap-4 bg-slate-50 dark:bg-slate-850 p-4 rounded-xl border border-slate-200 dark:border-slate-800 hover:border-primary-500/50 transition-all">
                            <div class="w-14 h-14 flex-shrink-0 rounded-lg bg-gradient-to-br from-amber-500 to-orange-600 flex items-center justify-center text-white">
                                <i class="fas fa-comments text-xl"></i>
                            </div>
                            <div>
                                <h4 class="font-bold text-slate-900 dark:text-white group-hover:text-primary-600 dark:group-hover:text-primary-400 transition-colors">How Large Language Models Work</h4>
                                <p class="text-sm text-slate-500 dark:text-slate-400">Van tokenization tot inference: LLMs van binnenuit.</p>
                            </div>
                        </a>
                        <a href="../ai-ml-dl-genai/" class="group flex gap-4 bg-slate-50 dark:bg-slate-850 p-4 rounded-xl border border-slate-200 dark:border-slate-800 hover:border-primary-500/50 transition-all">
                            <div class="w-14 h-14 flex-shrink-0 rounded-lg bg-gradient-to-br from-purple-500 to-indigo-600 flex items-center justify-center text-white">
                                <i class="fas fa-brain text-xl"></i>
                            </div>
                            <div>
                                <h4 class="font-bold text-slate-900 dark:text-white group-hover:text-primary-600 dark:group-hover:text-primary-400 transition-colors">AI vs ML vs DL vs GenAI</h4>
                                <p class="text-sm text-slate-500 dark:text-slate-400">Waar Transformers passen in de AI-hiërarchie.</p>
                            </div>
                        </a>
                    </div>
                </div>

                <!-- CTA -->
                <div class="mt-16 bg-gradient-to-r from-purple-500/10 to-violet-500/10 rounded-2xl p-8 border border-purple-500/20 text-center">
                    <h3 class="text-2xl font-display font-bold text-slate-900 dark:text-white mb-4">Transformer-gebaseerde AI implementeren?</h3>
                    <p class="text-slate-600 dark:text-slate-400 mb-6 max-w-2xl mx-auto">
                        Van fine-tuning tot deployment — wij helpen u LLMs in productie te brengen.
                    </p>
                    <a href="../../#contact" class="inline-block px-8 py-4 bg-purple-600 hover:bg-purple-700 text-white font-bold rounded-xl transition-all shadow-lg shadow-purple-500/25 hover:-translate-y-0.5">
                        Neem contact op
                    </a>
                </div>

            </div>
        </div>
    </article>

    <!-- Footer -->
    <footer class="py-8 bg-slate-100 dark:bg-slate-950 border-t border-slate-200 dark:border-slate-800 transition-colors duration-300">
        <div class="container mx-auto px-4 text-center">
            <p class="text-slate-500 text-sm">&copy; Virtunet B.V.</p>
        </div>
    </footer>

    <!-- Scripts -->
    <script>
        // Mobile menu toggle
        const btn = document.getElementById('mobile-menu-btn');
        const menu = document.getElementById('mobile-menu');
        btn.addEventListener('click', () => menu.classList.toggle('hidden'));

        // Theme toggle
        function toggleTheme() {
            document.documentElement.classList.toggle('dark');
            localStorage.setItem('theme', document.documentElement.classList.contains('dark') ? 'dark' : 'light');
        }

        // Load theme preference
        if (localStorage.getItem('theme') === 'dark' || (!localStorage.getItem('theme') && window.matchMedia('(prefers-color-scheme: dark)').matches)) {
            document.documentElement.classList.add('dark');
        }
    </script>
</body>
</html>
